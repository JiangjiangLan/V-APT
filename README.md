# V-APT: Action Recognition Based on Image to Video Prompt-Tuning

# Introduction
We propose the V-APT method, which incorporates a lightweight LSTM block for temporal relationship modeling before average temporal pooling. Furthermore, our approach also encompasses a deep visual and text prompt interaction block, which guides visual prompts through text prompts in order to ensure mutual coordination between vision and language.

# Method
![image](https://github.com/JiangjiangLan/V-APT/assets/73203790/bd8267b8-8b97-4ccb-98fa-20a7e2e7fc9e)

# Experiments
